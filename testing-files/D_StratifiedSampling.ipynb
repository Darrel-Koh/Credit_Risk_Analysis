{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from datetime import datetime\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_val_predict,cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data \n",
    "\n",
    "df = pd.read_csv('../data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the null value in each attributes\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_rev_hi_lim \n",
    "\n",
    "# Fill missing values in total_rev_hi_lim with Simple Imputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "total_rev_hi_lim = df['total_rev_hi_lim'].values.reshape(-1,1)\n",
    "total_rev_hi_lim_imputed = imputer.fit_transform(total_rev_hi_lim)\n",
    "df['total_rev_hi_lim'] = total_rev_hi_lim_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home_ownership \n",
    "\n",
    "# Remove rows with value ANY\n",
    "\n",
    "df = df[df['home_ownership'] != 'ANY']\n",
    "df['home_ownership'].unique()\n",
    "\n",
    "# Level encoding for home ownership \n",
    "\n",
    "home_type = ['RENT', 'OWN', 'MORTGAGE', 'OTHER', 'NONE']  # Unique values for encoding\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the grades\n",
    "encoder.fit(home_type)\n",
    "\n",
    "# Encode the 'grade' column in the DataFrame\n",
    "df['home_ownership'] = encoder.transform(df['home_ownership'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose \n",
    "\n",
    "# Label encoding for purpose\n",
    "\n",
    "df['purpose'].unique()\n",
    "\n",
    "purposes = ['credit_card', 'car', 'small_business', 'other', 'wedding',\n",
    "       'debt_consolidation', 'home_improvement', 'major_purchase',\n",
    "       'medical', 'moving', 'vacation', 'house', 'renewable_energy',\n",
    "       'educational']\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the grades\n",
    "encoder.fit(purposes)\n",
    "# Encode the 'grade' column in the DataFrame\n",
    "df['purpose'] = encoder.transform(df['purpose'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_grade\n",
    "\n",
    "# Sort the order of subgrades and do label encoding\n",
    "\n",
    "subgrades = ['B2', 'C4', 'C5', 'C1', 'B5', 'A4', 'E1', 'F2', 'C3', 'B1', 'D1',\n",
    "       'A1', 'B3', 'B4', 'C2', 'D2', 'A3', 'A5', 'D5', 'A2', 'E4', 'D3',\n",
    "       'D4', 'F3', 'E3', 'F4', 'F1', 'E5', 'G4', 'E2', 'G3', 'G2', 'G1',\n",
    "       'F5', 'G5']\n",
    "\n",
    "def custom_sort_key(subgrade):\n",
    "    match = re.match(r'([A-Za-z]+)(\\d+)', subgrade)\n",
    "    letter = match.group(1)\n",
    "    number = int(match.group(2))\n",
    "    \n",
    "    return letter, number\n",
    "\n",
    "sorted_subgrades = sorted(subgrades, key=custom_sort_key)\n",
    "\n",
    "# Level encoding for sorted sub-grade \n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the grades\n",
    "encoder.fit(sorted_subgrades)\n",
    "\n",
    "# Encode the 'grade' column in the DataFrame\n",
    "df['sub_grade'] = encoder.transform(df['sub_grade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# employment_lengths\n",
    "\n",
    "employment_lengths = ['< 1 year', '1 year', '2 years', '3 years', '4 years', '5 years', '6 years', '7 years', '8 years', '9 years', '10+ years', 'nan']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the LabelEncoder with unique values\n",
    "label_encoder.fit(employment_lengths)\n",
    "\n",
    "# Encode the attribute values\n",
    "df['emp_length'] = label_encoder.transform(df['emp_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mths_since_last_delinq\n",
    "\n",
    "df['mths_since_last_delinq'] = df['mths_since_last_delinq'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mths_since_last_record\n",
    "\n",
    "df['mths_since_last_record'] = df['mths_since_last_record'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revol_util\n",
    "# Handle missing value with imputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "revol_util = df['revol_util'].values.reshape(-1,1)\n",
    "\n",
    "revol_util_imputed = imputer.fit_transform(revol_util)\n",
    "\n",
    "df['revol_util'] = revol_util_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate annual_inc and annual_inc_joint\n",
    "\n",
    "df.loc[df['application_type'] == 'JOINT', 'annual_inc'] = df.loc[df['application_type'] == 'JOINT', 'annual_inc_joint']\n",
    "df = df.drop('annual_inc_joint', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dti_joint\n",
    "\n",
    "df.loc[df['application_type'] == 'JOINT', 'dti'] = df.loc[df['application_type'] == 'JOINT', 'dti_joint']\n",
    "df = df.drop('dti_joint', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verification_status_joint\n",
    "\n",
    "df.loc[df['application_type'] == 'JOINT', 'verification_status'] = df.loc[df['application_type'] == 'JOINT', 'verification_status_joint']\n",
    "df = df.drop('verification_status_joint', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# term \n",
    "# Label encoding for term\n",
    "\n",
    "term = [' 36 months', ' 60 months']  # Unique values for encoding\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the grades\n",
    "encoder.fit(term)\n",
    "\n",
    "# Encode the 'grade' column in the DataFrame\n",
    "df['term'] = encoder.transform(df['term'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verification_status\n",
    "\n",
    "veri = ['Not Verified', 'Source Verified', 'Verified']  # Unique values for encoding\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(veri)\n",
    "\n",
    "\n",
    "df['verification_status'] = encoder.transform(df['verification_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pymnt_plan\n",
    "\n",
    "plan = ['n', 'y']  # Unique values for encoding\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(plan)\n",
    "df['pymnt_plan'] = encoder.transform(df['pymnt_plan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# application_type\n",
    "\n",
    "type = ['INDIVIDUAL', 'JOINT'] # Unique values for encoding\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(type)\n",
    "\n",
    "df['application_type'] = encoder.transform(df['application_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initial_list_status\n",
    "\n",
    "status = ['f', 'w'] # Unique values for encoding\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(status)\n",
    "\n",
    "df['initial_list_status'] = encoder.transform(df['initial_list_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing last credit pull\n",
    "df['last_credit_pull_d'].fillna(\"25-07-2023\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit History Length:\n",
    "# Calculated as: last_credit_pull - earliest_cr_line\n",
    "def date_difference(date_str1, date_str2):\n",
    "    # Convert date strings to datetime objects\n",
    "    date_format = \"%d-%m-%Y\"\n",
    "    date1 = datetime.strptime(date_str1, date_format)\n",
    "    date2 = datetime.strptime(date_str2, date_format)\n",
    "\n",
    "    # Calculate the difference\n",
    "    difference = date2 - date1\n",
    "\n",
    "    # Return the difference in days\n",
    "    return difference.days\n",
    "\n",
    "df['credit_history_length'] = df.apply(lambda row: date_difference(row['earliest_cr_line'], row['last_credit_pull_d']), axis=1)\n",
    "\n",
    "# Swap the values and column names\n",
    "df['default_ind'], df['credit_history_length'] = df['credit_history_length'], df['default_ind']\n",
    "df.rename(columns={'default_ind': 'credit_history_length', 'credit_history_length': 'default_ind'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop not usable attributes \n",
    "\n",
    "remove_col = [\n",
    "    'id',\n",
    "    'member_id',\n",
    "    'emp_title',\n",
    "    'issue_d',\n",
    "    'desc',\n",
    "    'title',\n",
    "    'zip_code',\n",
    "    'addr_state',\n",
    "    'earliest_cr_line',\n",
    "    'last_pymnt_d',\n",
    "    'last_pymnt_amnt',\n",
    "    'next_pymnt_d',\n",
    "    'last_credit_pull_d',\n",
    "    'collections_12_mths_ex_med',\n",
    "    'mths_since_last_major_derog',\n",
    "    'policy_code',\n",
    "    'tot_coll_amt',\n",
    "    'tot_cur_bal', \n",
    "    'open_acc_6m',\n",
    "    'open_il_6m', \n",
    "    'open_il_12m', \n",
    "    'open_il_24m', \n",
    "    'mths_since_rcnt_il', \n",
    "    'total_bal_il', \n",
    "    'il_util', \n",
    "    'open_rv_12m' ,\n",
    "    'open_rv_24m', \n",
    "    'max_bal_bc', \n",
    "    'all_util', \n",
    "    'inq_fi', \n",
    "    'total_cu_tl', \n",
    "    'inq_last_12m',\n",
    "    'grade'\n",
    "]\n",
    "\n",
    "df = df.drop(remove_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize default_ind attribute\n",
    "\n",
    "sns.countplot(data=df, x='default_ind')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New feature using user defined transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreditUtilizationRatioTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, include=True):\n",
    "        self.revol_bal_col = 'revol_bal'\n",
    "        self.annual_inc_col = 'annual_inc'\n",
    "        self.installment_col = 'installment'\n",
    "        self.total_rec_prncp_col = 'total_rec_prncp'\n",
    "        self.funded_amnt_col = 'funded_amnt'\n",
    "\n",
    "        self.include_rev_to_inc_ratio = include\n",
    "        self.include_loan_to_inc_ratio = include\n",
    "        self.include_repayment_progress = include\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Find index of columns\n",
    "        revol_bal_ix = np.where(X.columns == self.revol_bal_col)[0][0]\n",
    "        annual_inc_ix = np.where(X.columns == self.annual_inc_col)[0][0]\n",
    "        installment_ix = np.where(X.columns == self.installment_col)[0][0]\n",
    "        total_rec_prncp_ix = np.where(X.columns == self.total_rec_prncp_col)[0][0]\n",
    "        funded_amnt_ix = np.where(X.columns == self.funded_amnt_col)[0][0]\n",
    "\n",
    "        # Calculate the Revolving Credit Balance to Annual Income Ratio.\n",
    "        rev_to_inc_ratio = X.iloc[:, revol_bal_ix] / X.iloc[:, annual_inc_ix]\n",
    "\n",
    "        # Calculate the Loan Payment-to-Income Ratio.\n",
    "        loan_to_inc_ratio = X.iloc[:, installment_ix] / (X.iloc[:, annual_inc_ix] / 12)\n",
    "\n",
    "        # Calculate the Repayment Progress.\n",
    "        repayment_progress = (X.iloc[:, total_rec_prncp_ix] / X.iloc[:, funded_amnt_ix]) * 100\n",
    "\n",
    "        # Create a copy of the original DataFrame to avoid modifying it directly\n",
    "        X_transformed = X.copy()\n",
    "\n",
    "        # Add the new columns to the DataFrame using .loc\n",
    "        if self.include_rev_to_inc_ratio:\n",
    "            X_transformed.loc[:, 'Rev_to_Inc_Ratio'] = rev_to_inc_ratio\n",
    "\n",
    "        if self.include_loan_to_inc_ratio:\n",
    "            X_transformed.loc[:, 'Loan_Payment_to_Income_Ratio'] = loan_to_inc_ratio\n",
    "\n",
    "        if self.include_repayment_progress:\n",
    "            X_transformed.loc[:, 'Repayment_Progress'] = repayment_progress\n",
    "\n",
    "        return X_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize - Correlation matrix\n",
    "\n",
    "# Create a correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Select the correlation values with 'default_ind'\n",
    "target_corr = corr_matrix['default_ind']\n",
    "\n",
    "# Plot the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 style=\"font-weight: bold;\">Model selections and trainings</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes (NB) Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB classifier using oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a: Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features (subset of columns from the original dataset)\n",
    "selected_features = ['recoveries', 'collection_recovery_fee', 'out_prncp', 'out_prncp_inv', 'sub_grade', 'revol_bal', 'annual_inc', 'installment', 'total_rec_prncp', 'funded_amnt']\n",
    "\n",
    "# Create the feature matrix X by selecting the columns from the original dataset\n",
    "X_beforeTransformed= df[selected_features]\n",
    "y = df['default_ind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Oversampling(X, y, test_size=0.2, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y, random_state=random_state)\n",
    "    # Instantiate the SMOTE object\n",
    "    smote = SMOTE(random_state=42)\n",
    "\n",
    "    # Perform SMOTE only on the training data\n",
    "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "    return X_train_balanced, X_test, y_train_balanced, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = Oversampling(X_beforeTransformed, y)\n",
    "nb_classifier_over = GaussianNB()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "nb_classifier_over.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_o = nb_classifier_over.predict(X2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (KNN) Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Fresh round of training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a: Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features (subset of columns from the original dataset)\n",
    "selected_features = ['recoveries', 'collection_recovery_fee', 'out_prncp', 'out_prncp_inv', 'sub_grade', 'revol_bal', 'annual_inc', 'installment', 'total_rec_prncp', 'funded_amnt']\n",
    "\n",
    "# Create the feature matrix X by selecting the columns from the original dataset\n",
    "X_beforeTransformed= df[selected_features]\n",
    "y = df['default_ind']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b: StratifiedShuffleSplit Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the StratifiedShuffleSplit object\n",
    "stratified_shuffle_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform the split and obtain the indices for training and testing sets\n",
    "for train_index, test_index in stratified_shuffle_split.split(X_beforeTransformed, y):\n",
    "    X_train, X_test = X_beforeTransformed.iloc[train_index], X_beforeTransformed.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation of Test and Train shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result: Significantly imbalanced class distribution\n",
    "\n",
    "#### Solution: Have to apply class balancing techniques (e.g. oversampling/SMOTE, or Class-Weighted approach) just before Model training\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c: Basic K-Neighbour Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  set the weights parameter to 'distance'\n",
    "# 'distance' means weights are assigned based on the inverse of the distance\n",
    "basic_classifier = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "\n",
    "# Train the classifier on the training data with class weights\n",
    "basic_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "basic_y_pred = basic_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Fine tune the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a: Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the nearest n_neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of n_neighbors to test\n",
    "param_grid = {'n_neighbors': range(1, 21)}\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "classifier = KNeighborsClassifier(weights='distance')\n",
    "\n",
    "# Use GridSearchCV or RandomizedSearchCV for hyperparameter tuning\n",
    "# For GridSearchCV:\n",
    "grid_search = GridSearchCV(classifier, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# For RandomizedSearchCV:\n",
    "# randomized_search = RandomizedSearchCV(classifier, param_distributions=param_grid, cv=5, scoring='accuracy', n_jobs=-1, n_iter=10)\n",
    "# randomized_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding performance\n",
    "print(\"Best n_neighbors:\", grid_search.best_params_['n_neighbors'])\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b: + User-defined Transformer Features to X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of CreditUtilizationRatioTransformer with desired features included\n",
    "transformer = CreditUtilizationRatioTransformer(\n",
    "    include= True\n",
    ")\n",
    "# Apply the transformer to add the new features to X\n",
    "X = transformer.transform(X_beforeTransformed)\n",
    "\n",
    "# Now X contains the original selected features along with additional features from the transformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c: Training KNN Model using SMOTE approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the SMOTE object\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Perform SMOTE only on the training data\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising Data Shape Before and After SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before SMOTE\n",
    "print(\"Class distribution before SMOTE:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "\n",
    "# After SMOTE\n",
    "print(\"Class distribution after SMOTE:\")\n",
    "print(pd.Series(y_train_balanced).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier on the training data with SMOTE\n",
    "classifier_smote = KNeighborsClassifier(n_neighbors=4)\n",
    "classifier_smote.fit(X_train_balanced, y_train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set using the trained model\n",
    "smote_y_pred = classifier_smote.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics for the test set\n",
    "accuracy_smote = accuracy_score(y_test, smote_y_pred)\n",
    "roc_auc_smote = roc_auc_score(y_test, smote_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d: Training KNN Model using Class-Weighted approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training  Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  set the weights parameter to 'distance'\n",
    "# 'distance' means weights are assigned based on the inverse of the distance\n",
    "class_classifier = KNeighborsClassifier(n_neighbors=4, weights='distance')\n",
    "\n",
    "# Train the classifier on the training data with class weights\n",
    "class_classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing data\n",
    "class_y_pred = class_classifier.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "class_accuracy = accuracy_score(y_test, class_y_pred)\n",
    "roc_auc = roc_auc_score(y_test, class_y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3)Evaluate the outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3a: Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(y_true, y_pred, model_name):\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    # Generate the confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Display the confusion matrix as a heatmap\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Non-default', 'Default'], yticklabels=['Non-default', 'Default'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(model_name)\n",
    "    plt.show()\n",
    "\n",
    "    # Generate the classification report\n",
    "    report = classification_report(y_true, y_pred, target_names=['Non-default', 'Default'], output_dict=True)\n",
    "\n",
    "    # Create a summary table\n",
    "    summary_table = pd.DataFrame({\n",
    "        'Model': [model_name],\n",
    "        'Accuracy': [accuracy],\n",
    "        'ROC-AUC Score': [roc_auc],\n",
    "        'Precision (Non-default)': [report['Non-default']['precision']],\n",
    "        'Recall (Non-default)': [report['Non-default']['recall']],\n",
    "        'F1-score (Non-default)': [report['Non-default']['f1-score']],\n",
    "        'Precision (Default)': [report['Default']['precision']],\n",
    "        'Recall (Default)': [report['Default']['recall']],\n",
    "        'F1-score (Default)': [report['Default']['f1-score']],\n",
    "    })\n",
    "\n",
    "    return summary_table\n",
    "\n",
    "# Usage:\n",
    "basic_summary = evaluate_predictions(y_test, basic_y_pred, \"Basic Model\")\n",
    "smote_summary = evaluate_predictions(y_test, smote_y_pred, \"Balanced Model\")\n",
    "class_summary = evaluate_predictions(y_test, class_y_pred, \"Class Model\")\n",
    "\n",
    "# Combine all summaries into one DataFrame\n",
    "all_summaries = pd.concat([basic_summary, smote_summary, class_summary], ignore_index=True)\n",
    "\n",
    "# Display the summary table\n",
    "print(all_summaries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3b: Conclusion: Since Class-Weighted approach with the optimal n_neighbors=4 have better scores across almost all metrics, therefore it is best to use this approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
